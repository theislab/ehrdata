{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting, Representing, Validating and Visualizing Data from an OMOP CDM Database with ehrdata, lamin and Vitessce\n",
    "\n",
    "## Background\n",
    "\n",
    "In a nutshell\n",
    "1. Extract data from a database of the [OMOP Common Data Model](https://ohdsi.github.io/CommonDataModel/index.html)\n",
    "2. Represent this data in an [ehrdata](https://ehrdata.readthedocs.io/en/latest/#) object\n",
    "3. Validate this ehrdata object using [lamin](https://lamin.ai/) functionality (optional but recommended)\n",
    "4. Visualize this data with [Vitessce](https://vitessce.io/), either in a notebook or on cloud storage via lamin hub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OMOP\n",
    "[OMOP](https://ohdsi.github.io/CommonDataModel/index.html) is a data model by [OHDSI](https://www.ohdsi.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Example Dataset used: MIMIC IV OMOP Demo Dataset\n",
    "Dataset available on [Physionet](https://physionet.org/content/mimic-iv-demo-omop/0.9/).\n",
    "\n",
    "Dataset:<br>\n",
    "Kallfelz, M., Tsvetkova, A., Pollard, T., Kwong, M., Lipori, G., Huser, V., Osborn, J., Hao, S., & Williams, A. (2021). MIMIC-IV demo data in the OMOP Common Data Model (version 0.9). PhysioNet. https://doi.org/10.13026/p1f5-7x35.\n",
    "\n",
    "Physionet:<br>\n",
    "Goldberger, A., Amaral, L., Glass, L., Hausdorff, J., Ivanov, P. C., Mark, R., ... & Stanley, H. E. (2000). PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals. Circulation [Online]. 101 (23), pp. e215–e220.\n",
    "\n",
    "### Extract\n",
    "This notebook guides you through the extraction from data following the OMOP CDM.\n",
    "\n",
    "### Represent\n",
    "See [ehrdata](https://ehrdata.readthedocs.io/en/latest/#) for more information on ehrdata.\n",
    "\n",
    "### Validate\n",
    "See [lamin](https://lamin.ai/) for more information on lamin.\n",
    "\n",
    "### Visualize\n",
    "See [Vitessce](https://vitessce.io/) for more information on Vitessce\n",
    "\n",
    "## The extraction workflow\n",
    "\n",
    "Here, we use [duckdb](https://duckdb.org/)'s Python API to load csv tables as they are available from the link above. (which is absolutely useless for immediate purposes but why not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import duckdb\n",
    "import ehrapy as ep\n",
    "import ehrdata as ed\n",
    "import ehrdata\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from widgets import create_single_option_widget, create_multiple_options_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = [\"person\", \"person_cohort\", \"person_observation_period\", \"person_visit_occurence\"]\n",
    "\n",
    "\n",
    "ui_obs, selected_obs = create_single_option_widget(\n",
    "    title_text=\"Please select which table should be used for .obs indexing in ehrdata:\",\n",
    "    options=options,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = [\"measurement\", \"observation\", \"drug_occurrence\"]\n",
    "ui_var, selected_vars = create_multiple_options_widget(title_text=\"Options to use as the variables\", options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = [\n",
    "    \"pca\",\n",
    "    \"umap\",\n",
    "]\n",
    "ui_emb, selected_emb = create_single_option_widget(\n",
    "    title_text=\"Please select which embedding do you want to use:\",\n",
    "    options=options,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a local database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data into your database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m!\u001b[0m File ehrapy_data/mimic-iv-demo-data-in-the-omop-common-data-model-0.9/mimic-iv-demo-data-in-the-omop-common-data-model-0.9 already exists! Using already downloaded dataset...\n"
     ]
    }
   ],
   "source": [
    "ehrdata.dt.mimic_iv_omop(backend_handle=con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what tables there are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>care_site</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cdm_source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cohort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cohort_definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>concept_relationship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>condition_era</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>condition_occurrence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>device_exposure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dose_era</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>drug_era</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>drug_exposure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fact_relationship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>measurement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>metadata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>note</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>note_nlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>observation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>observation_period</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>payer_plan_period</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>procedure_occurrence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>provider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>specimen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>visit_detail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>visit_occurrence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>vocabulary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name\n",
       "0              care_site\n",
       "1             cdm_source\n",
       "2                 cohort\n",
       "3      cohort_definition\n",
       "4                concept\n",
       "5   concept_relationship\n",
       "6          condition_era\n",
       "7   condition_occurrence\n",
       "8                   cost\n",
       "9                  death\n",
       "10       device_exposure\n",
       "11              dose_era\n",
       "12              drug_era\n",
       "13         drug_exposure\n",
       "14     fact_relationship\n",
       "15              location\n",
       "16           measurement\n",
       "17              metadata\n",
       "18                  note\n",
       "19              note_nlp\n",
       "20           observation\n",
       "21    observation_period\n",
       "22     payer_plan_period\n",
       "23                person\n",
       "24  procedure_occurrence\n",
       "25              provider\n",
       "26              specimen\n",
       "27          visit_detail\n",
       "28      visit_occurrence\n",
       "29            vocabulary"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables = con.execute(\"SHOW TABLES;\").df()\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94f866cb87c410e850f35a41dcb98e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Please select which table should be used for .obs indexing in ehrdata:</h3>'), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ui_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EHRData object with n_obs × n_vars = 100 × 0\n",
       "    obs: 'person_id', 'gender_concept_id', 'year_of_birth', 'month_of_birth', 'day_of_birth', 'birth_datetime', 'race_concept_id', 'ethnicity_concept_id', 'location_id', 'provider_id', 'care_site_id', 'person_source_value', 'gender_source_value', 'gender_source_concept_id', 'race_source_value', 'race_source_concept_id', 'ethnicity_source_value', 'ethnicity_source_concept_id', 'observation_period_id', 'person_id_1', 'observation_period_start_date', 'observation_period_end_date', 'period_type_concept_id'\n",
       "    uns: 'omop_io_observation_table'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if obs_base.value == 'person':\n",
    "#     obs = ehrdata.io.omop.extract_person(con)\n",
    "# elif obs_base.value == 'observation_period':\n",
    "#     obs = ehrdata.io.omop.extract_observation_period(con)\n",
    "# elif obs_base.value == 'visit_occurrence':\n",
    "#     obs = ehrdata.io.omop.extract_visit_occurrence(con)\n",
    "# elif obs_base.value == 'condition_occurrence':\n",
    "#     obs = ehrdata.io.omop.extract_condition_occurrence(con)\n",
    "\n",
    "# obs.head()\n",
    "\n",
    "if selected_obs.value == \"person\":\n",
    "    edata = ed.io.omop.setup_obs(con, \"person\") \n",
    "elif selected_obs.value == \"person_cohort\": # person cohort = 0 x 0?\n",
    "    edata = ed.io.omop.setup_obs(con, \"person_cohort\") \n",
    "elif selected_obs.value == \"person_observation_period\":\n",
    "    edata = ed.io.omop.setup_obs(con, \"person_observation_period\")\n",
    "elif selected_obs.value == \"person_visit_occurrence\":\n",
    "    edata = ed.io.omop.setup_obs(con, \"person_visit_occurrence\")\n",
    "\n",
    "edata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interlude - Irregularly sampled time series data\n",
    "Electronic health records can be regarded as (that is, form a model of a person via) irregular sampling irregularly sampled time series.\n",
    "\n",
    "Following notation and explanation from [Horn et al.](https://proceedings.mlr.press/v119/horn20a.html), a time series of a patient can be described as a set of tuples (t, z, m), where t denotes the time, z the observed value, and m a modality description of the measurement.\n",
    "\n",
    "The time series can have different lengths, and a \"typical\" number of observed values might not exist.\n",
    "\n",
    "Generally, an irregularly-sampled time series can be converted into a missing data problem by discretizing the time axis into non-overlapping intervals, and declaring intervals in which no data was sampled as missing (Bahadori & Lipton, 2019). [Horn et al.](https://proceedings.mlr.press/v119/horn20a.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd4870aba794927b5b450986f8a1814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<h3 style='color: #333; font-family: Arial, sans-serif;'>Options to use as the vari…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ui_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:multiple units for features: [[  9]\n",
      " [ 16]\n",
      " [ 18]\n",
      " [ 28]\n",
      " [ 39]\n",
      " [ 54]\n",
      " [ 71]\n",
      " [ 74]\n",
      " [ 86]\n",
      " [138]\n",
      " [160]\n",
      " [179]\n",
      " [196]\n",
      " [202]\n",
      " [220]\n",
      " [244]\n",
      " [332]\n",
      " [339]\n",
      " [389]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept_id</th>\n",
       "      <th>unit_concept_id</th>\n",
       "      <th>no_units</th>\n",
       "      <th>multiple_units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3007733</td>\n",
       "      <td>9557</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3006175</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3009201</td>\n",
       "      <td>9093</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3014037</td>\n",
       "      <td>8784</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3004295</td>\n",
       "      <td>8840</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>3022094</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>3024463</td>\n",
       "      <td>9461</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>4046245</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>3002091</td>\n",
       "      <td>9550</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>3008295</td>\n",
       "      <td>8862</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     concept_id  unit_concept_id  no_units  multiple_units\n",
       "0       3007733             9557     False           False\n",
       "1       3006175             <NA>     False           False\n",
       "2       3009201             9093     False           False\n",
       "3       3014037             8784     False           False\n",
       "4       3004295             8840     False           False\n",
       "..          ...              ...       ...             ...\n",
       "436     3022094             <NA>     False           False\n",
       "437     3024463             9461     False           False\n",
       "438     4046245             <NA>     False           False\n",
       "439     3002091             9550     False           False\n",
       "440     3008295             8862     False           False\n",
       "\n",
       "[441 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edata = ed.io.omop.setup_variables(\n",
    "    edata=edata,\n",
    "    backend_handle=con,\n",
    "    data_tables=list(selected_vars.value),\n",
    "    data_field_to_keep=[\"value_as_number\"],\n",
    "    interval_length_number=20,\n",
    "    interval_length_unit=\"day\",\n",
    "    num_intervals=10,\n",
    "    concept_ids=\"all\",\n",
    "    aggregation_strategy=\"last\",\n",
    "    enrich_var_with_feature_info=True,\n",
    "    enrich_var_with_unit_info=False,\n",
    ")\n",
    "edata.uns[\"unit_report_measurement\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EHRData object with n_obs × n_vars × n_t = 100 × 450 × 10\n",
       "    obs: 'person_id', 'gender_concept_id', 'year_of_birth', 'month_of_birth', 'day_of_birth', 'birth_datetime', 'race_concept_id', 'ethnicity_concept_id', 'location_id', 'provider_id', 'care_site_id', 'person_source_value', 'gender_source_value', 'gender_source_concept_id', 'race_source_value', 'race_source_concept_id', 'ethnicity_source_value', 'ethnicity_source_concept_id', 'observation_period_id', 'person_id_1', 'observation_period_start_date', 'observation_period_end_date', 'period_type_concept_id'\n",
       "    var: 'data_table_concept_id', 'concept_id', 'concept_name', 'domain_id', 'vocabulary_id', 'concept_class_id', 'standard_concept', 'concept_code', 'valid_start_date', 'valid_end_date', 'invalid_reason'\n",
       "    tem: '0', '1', '2', '3', '4', '5', '6', '7', '8', '9'\n",
       "    uns: 'omop_io_observation_table', 'unit_report_measurement'\n",
       "    shape of .X: (100, 450)\n",
       "    shape of .R: (100, 450, 10)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "edata.X = np.nanmean(edata.R, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[100]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mep\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmissing_values_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43medata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/hatch/env/virtual/ehrdata/PaRdwTqs/ehrdata/lib64/python3.13/site-packages/ehrapy/plot/_missingno_pl_api.py:61\u001b[39m, in \u001b[36mmissing_values_matrix\u001b[39m\u001b[34m(adata, filter, max_cols, max_percentage, sort, figsize, width_ratios, color, fontsize, labels, label_rotation, sparkline, categoricals)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m categoricals:\n\u001b[32m     60\u001b[39m     non_categorical_columns = [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m col.startswith(\u001b[33m\"\u001b[39m\u001b[33mehrapycat\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmsno\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnon_categorical_columns\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwidth_ratios\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfontsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel_rotation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m        \u001b[49m\u001b[43msparkline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m msno.matrix(\n\u001b[32m     77\u001b[39m         df,\n\u001b[32m     78\u001b[39m         \u001b[38;5;28mfilter\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     88\u001b[39m         sparkline,\n\u001b[32m     89\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/hatch/env/virtual/ehrdata/PaRdwTqs/ehrdata/lib64/python3.13/site-packages/missingno/missingno.py:86\u001b[39m, in \u001b[36mmatrix\u001b[39m\u001b[34m(df, filter, n, p, sort, figsize, width_ratios, color, fontsize, labels, label_rotation, sparkline, freq, ax)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mor\u001b[39;00m (labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(df.columns) <= \u001b[32m50\u001b[39m):\n\u001b[32m     85\u001b[39m     ha = \u001b[33m'\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     \u001b[43max0\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_xticks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m     ax0.set_xticklabels(\u001b[38;5;28mlist\u001b[39m(df.columns), rotation=label_rotation, ha=ha, fontsize=fontsize)\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/hatch/env/virtual/ehrdata/PaRdwTqs/ehrdata/lib64/python3.13/site-packages/matplotlib/axes/_base.py:74\u001b[39m, in \u001b[36m_axis_method_wrapper.__set_name__.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/hatch/env/virtual/ehrdata/PaRdwTqs/ehrdata/lib64/python3.13/site-packages/matplotlib/axis.py:2218\u001b[39m, in \u001b[36mAxis.set_ticks\u001b[39m\u001b[34m(self, ticks, labels, minor, **kwargs)\u001b[39m\n\u001b[32m   2213\u001b[39m     first_key = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))\n\u001b[32m   2214\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2215\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIncorrect use of keyword argument \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfirst_key\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m. Keyword arguments \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2216\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mother than \u001b[39m\u001b[33m'\u001b[39m\u001b[33mminor\u001b[39m\u001b[33m'\u001b[39m\u001b[33m modify the text labels and can only be used if \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2217\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m'\u001b[39m\u001b[33m are passed as well.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2218\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_tick_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mminor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2219\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2220\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_ticklabels(labels, minor=minor, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/hatch/env/virtual/ehrdata/PaRdwTqs/ehrdata/lib64/python3.13/site-packages/matplotlib/axis.py:2170\u001b[39m, in \u001b[36mAxis._set_tick_locations\u001b[39m\u001b[34m(self, ticks, minor)\u001b[39m\n\u001b[32m   2168\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2169\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_major_locator(locator)\n\u001b[32m-> \u001b[39m\u001b[32m2170\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_major_ticks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mticks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/hatch/env/virtual/ehrdata/PaRdwTqs/ehrdata/lib64/python3.13/site-packages/matplotlib/axis.py:1664\u001b[39m, in \u001b[36mAxis.get_major_ticks\u001b[39m\u001b[34m(self, numticks)\u001b[39m\n\u001b[32m   1660\u001b[39m     numticks = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.get_majorticklocs())\n\u001b[32m   1662\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.majorTicks) < numticks:\n\u001b[32m   1663\u001b[39m     \u001b[38;5;66;03m# Update the new tick label properties from the old.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1664\u001b[39m     tick = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_tick\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmajor\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1665\u001b[39m     \u001b[38;5;28mself\u001b[39m.majorTicks.append(tick)\n\u001b[32m   1666\u001b[39m     \u001b[38;5;28mself\u001b[39m._copy_tick_props(\u001b[38;5;28mself\u001b[39m.majorTicks[\u001b[32m0\u001b[39m], tick)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/hatch/env/virtual/ehrdata/PaRdwTqs/ehrdata/lib64/python3.13/site-packages/matplotlib/axis.py:1592\u001b[39m, in \u001b[36mAxis._get_tick\u001b[39m\u001b[34m(self, major)\u001b[39m\n\u001b[32m   1588\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m   1589\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe Axis subclass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must define \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1590\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m_tick_class or reimplement _get_tick()\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1591\u001b[39m tick_kw = \u001b[38;5;28mself\u001b[39m._major_tick_kw \u001b[38;5;28;01mif\u001b[39;00m major \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._minor_tick_kw\n\u001b[32m-> \u001b[39m\u001b[32m1592\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tick_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmajor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmajor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtick_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/hatch/env/virtual/ehrdata/PaRdwTqs/ehrdata/lib64/python3.13/site-packages/matplotlib/axis.py:383\u001b[39m, in \u001b[36mXTick.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    378\u001b[39m trans, va, ha = \u001b[38;5;28mself\u001b[39m._get_text1_transform()\n\u001b[32m    379\u001b[39m \u001b[38;5;28mself\u001b[39m.label1.set(\n\u001b[32m    380\u001b[39m     x=\u001b[32m0\u001b[39m, y=\u001b[32m0\u001b[39m,\n\u001b[32m    381\u001b[39m     verticalalignment=va, horizontalalignment=ha, transform=trans,\n\u001b[32m    382\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m383\u001b[39m trans, va, ha = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_text2_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[38;5;28mself\u001b[39m.label2.set(\n\u001b[32m    385\u001b[39m     x=\u001b[32m0\u001b[39m, y=\u001b[32m1\u001b[39m,\n\u001b[32m    386\u001b[39m     verticalalignment=va, horizontalalignment=ha, transform=trans,\n\u001b[32m    387\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/hatch/env/virtual/ehrdata/PaRdwTqs/ehrdata/lib64/python3.13/site-packages/matplotlib/axis.py:393\u001b[39m, in \u001b[36mXTick._get_text2_transform\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    392\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_text2_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_xaxis_text2_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pad\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/hatch/env/virtual/ehrdata/PaRdwTqs/ehrdata/lib64/python3.13/site-packages/matplotlib/axes/_base.py:1040\u001b[39m, in \u001b[36m_AxesBase.get_xaxis_text2_transform\u001b[39m\u001b[34m(self, pad_points)\u001b[39m\n\u001b[32m   1020\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1021\u001b[39m \u001b[33;03mReturns\u001b[39;00m\n\u001b[32m   1022\u001b[39m \u001b[33;03m-------\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1037\u001b[39m \u001b[33;03mmay need to place axis elements in different locations.\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1039\u001b[39m labels_align = mpl.rcParams[\u001b[33m\"\u001b[39m\u001b[33mxtick.alignment\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m-> \u001b[39m\u001b[32m1040\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_xaxis_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwhich\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtick2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\n\u001b[32m   1041\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmtransforms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mScaledTranslation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1042\u001b[39m \u001b[43m            \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_points\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m72\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1043\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdpi_scale_trans\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1044\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbottom\u001b[39m\u001b[33m\"\u001b[39m, labels_align)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/hatch/env/virtual/ehrdata/PaRdwTqs/ehrdata/lib64/python3.13/site-packages/matplotlib/transforms.py:1347\u001b[39m, in \u001b[36mTransform.__add__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m   1340\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__add__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m   1341\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1342\u001b[39m \u001b[33;03m    Compose two transforms together so that *self* is followed by *other*.\u001b[39;00m\n\u001b[32m   1343\u001b[39m \n\u001b[32m   1344\u001b[39m \u001b[33;03m    ``A + B`` returns a transform ``C`` so that\u001b[39;00m\n\u001b[32m   1345\u001b[39m \u001b[33;03m    ``C.transform(x) == B.transform(A.transform(x))``.\u001b[39;00m\n\u001b[32m   1346\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1347\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mcomposite_transform_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1348\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, Transform) \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[32m   1349\u001b[39m             \u001b[38;5;28mNotImplemented\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/hatch/env/virtual/ehrdata/PaRdwTqs/ehrdata/lib64/python3.13/site-packages/matplotlib/transforms.py:2498\u001b[39m, in \u001b[36mcomposite_transform_factory\u001b[39m\u001b[34m(a, b)\u001b[39m\n\u001b[32m   2494\u001b[39m             \u001b[38;5;28mself\u001b[39m._invalid = \u001b[32m0\u001b[39m\n\u001b[32m   2495\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._mtx\n\u001b[32m-> \u001b[39m\u001b[32m2498\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcomposite_transform_factory\u001b[39m(a, b):\n\u001b[32m   2499\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2500\u001b[39m \u001b[33;03m    Create a new composite transform that is the result of applying\u001b[39;00m\n\u001b[32m   2501\u001b[39m \u001b[33;03m    transform a then transform b.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2510\u001b[39m \u001b[33;03m      c = a + b\u001b[39;00m\n\u001b[32m   2511\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   2512\u001b[39m     \u001b[38;5;66;03m# check to see if any of a or b are IdentityTransforms. We use\u001b[39;00m\n\u001b[32m   2513\u001b[39m     \u001b[38;5;66;03m# isinstance here to guarantee that the transforms will *always*\u001b[39;00m\n\u001b[32m   2514\u001b[39m     \u001b[38;5;66;03m# be IdentityTransforms. Since TransformWrappers are mutable,\u001b[39;00m\n\u001b[32m   2515\u001b[39m     \u001b[38;5;66;03m# use of equality here would be wrong.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "ep.pl.missing_values_matrix(edata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep.pp.explicit_impute(edata, replacement=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lamin Validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!lamin connect theislab/ehr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import omop as op\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edata.var.rename(columns={0: \"concept_id\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concepts vocabulary from OMOP. Intersection with ehdata.var\n",
    "omop_concepts = pd.read_csv(\"./metadata/omop_validation_slice.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edata.var.concept_id.isin(omop_concepts.concept_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(edata.var, omop_concepts, on=\"concept_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the type to match `omop.Concept` typing\n",
    "omop_concepts = omop_concepts.astype(\n",
    "    {\n",
    "        \"standard_concept\": \"str\",\n",
    "        \"invalid_reason\": \"str\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULTS_VALUES_VAR = {\n",
    "    \"concept_id\": int,\n",
    "    \"concept_name\": str,\n",
    "    \"domain_id\": str,\n",
    "    \"vocabulary_id\": str,\n",
    "    \"concept_class\": str,\n",
    "    \"standard_concept\": (str, type(None)),\n",
    "    \"concept_code\": str,\n",
    "    \"valid_start_date\": str,\n",
    "    \"valid_end_date\": str,\n",
    "    \"invalid_reason\": (str, type(None)),\n",
    "}\n",
    "\n",
    "for column, expected_type in DEFAULTS_VALUES_VAR.items():\n",
    "    # Check if the column exists in the DataFrame\n",
    "    if column not in omop_concepts.columns:\n",
    "        msg = f\"Required column '{column}' is missing from the DataFrame.\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    # Adjust type check for string columns (object is the pandas dtype for strings)\n",
    "    if expected_type is str:\n",
    "        if omop_concepts[column].dtype != \"object\":\n",
    "            msg = f\"Column '{column}' has incorrect data type. Expected string (object in pandas).\"\n",
    "            raise TypeError(msg)\n",
    "    elif isinstance(expected_type, tuple):  # For optional fields (e.g., str or None)\n",
    "        if not omop_concepts[column].map(lambda x, expected_type=expected_type: isinstance(x, expected_type)).all():\n",
    "            msg = f\"Column '{column}' has incorrect data type. Expected one of {expected_type}.\"\n",
    "            raise TypeError(msg)\n",
    "    elif not omop_concepts[column].map(lambda x, expected_type=expected_type: isinstance(x, expected_type)).all():\n",
    "        msg = f\"Column '{column}' has incorrect data type. Expected {expected_type.__name__}.\"\n",
    "        raise TypeError(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Push to lamin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip, concepts already pushed Lamin\n",
    "concepts = [op.Concept(**row.to_dict()) for _, row in omop_concepts.iterrows()]\n",
    "for concept in concepts:\n",
    "    concept.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EHR curator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curator = ehrdata.tl.EHRCurator(\n",
    "    edata=edata,\n",
    "    concepts_var_column=\"concept_id\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edata = curator.validate_adata(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edata.var.valid_concept_id.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ui_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep.pp.pca(edata)\n",
    "if selected_emb.value == \"umap\":\n",
    "    ep.pp.neighbors(edata)\n",
    "    ep.tl.umap(edata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = ad.AnnData(X=edata.X, obs=edata.obs, var=edata.var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: why is any of this interesting?\n",
    "#### A: because now ehrapy and more tools in the future of its ecosystem (like with scanpy) can nicely access this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ep.tl.CohortTracker(\n",
    "    edata,\n",
    "    columns=[\n",
    "        \"gender_concept_id\",\n",
    "        \"year_of_birth\",\n",
    "        \"race_concept_id\",\n",
    "        \"period_type_concept_id\",\n",
    "    ],\n",
    "    categorical=[\"gender_concept_id\", \"race_concept_id\", \"period_type_concept_id\"],\n",
    ")\n",
    "\n",
    "ct(edata)\n",
    "\n",
    "ct.plot_cohort_barplot(\n",
    "    legend_labels={\n",
    "        # 0: \"Unknown\",\n",
    "        # 8516: \"Black or African American\",\n",
    "        # \"year_of_birth\": \"Birthyear (artificial)\",\n",
    "        # 8507: \"Male\",\n",
    "        # 8532: \"Female\",\n",
    "    },\n",
    "    legend_subtitles_names={\"gender_concept_id\": \"Gender\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization with Vitessce in notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from vitessce.data_utils import optimize_adata, VAR_CHUNK_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Save the AnnData object to Zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zarr_filepath = Path(\"data\", \"processed_ehrdata.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not zarr_filepath.is_dir():\n",
    "    edata = optimize_adata(\n",
    "        edata,\n",
    "        obs_cols=[\"gender_concept_id\", \"race_concept_id\"],\n",
    "        obsm_keys=[\"X_pca\", \"X_umap\"],\n",
    "        optimize_X=True,\n",
    "    )\n",
    "    edata.write_zarr(zarr_filepath, chunks=[edata.shape[0], VAR_CHUNK_SIZE])\n",
    "else:\n",
    "    print(f\"path exists, did not write new file: {zarr_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create a Vitessce view config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ehrdata.pl.vitessce\n",
    "\n",
    "vc = ehrdata.pl.vitessce.gen_config(zarr_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create the Vitessce widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lamindb as ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.connect(\"theislab/ehr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vw = vc.widget()\n",
    "vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../_static/tutorial_images/vitessce_screenshot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization with Vitessce on lamin\n",
    "Uploading dataset on lamin allows even easier sharing and looking at dataset together. Together with the dedicated validation functionality that lamin has and we might extend, this makes lamin + ehrdata a powerful coupling.\n",
    "\n",
    "**This requires to connect to lamindb from terminal to work!**\n",
    "```\n",
    "lamin login <credentials>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lamindb as ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zarr_artifact = ln.Artifact(\n",
    "    zarr_filepath,\n",
    "    description=\"Dummy EHRDataset\",\n",
    ")\n",
    "zarr_artifact.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = ehrdata.pl.vitessce.gen_config(artifact=zarr_artifact, url=zarr_artifact.path.to_url())\n",
    "vc.widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lamindb.integrations import save_vitessce_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc_artifact = save_vitessce_config(vc, description=\"Dummy OMOP prepared dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our data is stored on the cloud, managed by lamin:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../_static/tutorial_images/laminhub_screenshot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can share the data with others easily, and give them a look at it: all they need is access to our lamin storage & click the vitessce button next to the dataset in their browser!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Lamin utility\n",
    "Using lamin offers a lot of powerful tracking of our data and how we operated on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc_artifact.view_lineage()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hatch env ehrdata",
   "language": "python",
   "name": "ehrdataenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
