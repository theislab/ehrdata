{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning on OMOP Data in `EHRData` with `PyPOTS`\n",
    "\n",
    "This tutorial demonstrates how to quickly apply machine learning to OMOP data using [PyPOTS](https://github.com/WenjieDu/PyPOTS), a powerful toolkit for time series analysis.\n",
    "\n",
    "**Prerequisites:** Complete the [OMOP Introduction tutorial](omop_intro.ipynb) first to understand how to load OMOP data into EHRData.\n",
    "\n",
    "## Use Case: ICU Mortality Prediction\n",
    "\n",
    "We'll predict in-hospital mortality for ICU patients using the [MIMIC-IV demo dataset in OMOP format](https://physionet.org/content/mimic-iv-demo-omop/0.9/).\n",
    "\n",
    "```{note}\n",
    "This is a demonstration example. Real clinical prediction requires more sophisticated preprocessing, validation, and careful consideration of clinical context.\n",
    "```\n",
    "\n",
    "## What is PyPOTS?\n",
    "\n",
    "PyPOTS provides state-of-the-art neural network models for time series tasks:\n",
    "- **Imputation** - Fill missing values in incomplete time series\n",
    "- **Classification** - Predict outcomes from time series\n",
    "- **Forecasting** - Predict future values\n",
    "- **Clustering** - Group similar patients\n",
    "\n",
    "PyPOTS works seamlessly with EHRData objects!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pypots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyPOTS requires this for scipy compatibility\n",
    "import os\n",
    "\n",
    "os.environ[\"SCIPY_ARRAY_API\"] = \"1\"\n",
    "\n",
    "import ehrdata as ed\n",
    "import duckdb\n",
    "import numpy as np\n",
    "import torch\n",
    "from pypots.classification import BRITS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Database and Download Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create database connection\n",
    "con = duckdb.connect(\":memory:\")\n",
    "\n",
    "# Download MIMIC-IV OMOP demo data\n",
    "ed.dt.mimic_iv_omop(backend_handle=con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Cohort\n",
    "\n",
    "We'll focus on ICU patients by filtering `visit_occurrence` for ICU stays using OMOP concept IDs:\n",
    "- **4305366**: Surgical ICU\n",
    "- **40481392**: Medical ICU\n",
    "- **32037**: Intensive Care\n",
    "- **763903**: Trauma ICU\n",
    "- **4149943**: Cardiac ICU\n",
    "\n",
    "We apply two key filters:\n",
    "1. **Duration**: Only ICU stays >24 hours (to ensure sufficient data for 24-hour analysis)\n",
    "2. **First visit**: If a patient had multiple ICU stays, we select their **first ICU visit**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICU cohort: 99 patients (first ICU visit >24h only)\n"
     ]
    }
   ],
   "source": [
    "# Filter for first ICU visit per patient (>24 hours only)\n",
    "con.execute(\"\"\"\n",
    "    WITH RankedVisits AS (\n",
    "        SELECT\n",
    "            v.*,\n",
    "            vd.*,\n",
    "            ROW_NUMBER() OVER (PARTITION BY v.person_id ORDER BY v.visit_start_date) AS rn\n",
    "        FROM visit_occurrence v\n",
    "        JOIN visit_detail vd USING (visit_occurrence_id)\n",
    "        WHERE vd.visit_detail_concept_id IN (4305366, 40481392, 32037, 763903, 4149943)\n",
    "            AND date_diff('hour', v.visit_start_date, v.visit_end_date) > 24\n",
    "    ),\n",
    "    first_icu_visit_occurrence_id AS (\n",
    "        SELECT visit_occurrence_id\n",
    "        FROM RankedVisits\n",
    "        WHERE rn = 1\n",
    "    )\n",
    "    DELETE FROM visit_occurrence\n",
    "    WHERE visit_occurrence_id NOT IN (SELECT visit_occurrence_id FROM first_icu_visit_occurrence_id)\n",
    "\"\"\")\n",
    "\n",
    "# Check how many ICU visits remain\n",
    "n_visits = con.execute(\"SELECT COUNT(*) FROM visit_occurrence\").fetchone()[0]\n",
    "print(f\"ICU cohort: {n_visits} patients (first ICU visit >24h only)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build EHRData from OMOP\n",
    "\n",
    "Now we construct the EHRData object using **ICU visit start** as the time reference (t=0) for each patient:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created EHRData with 99 ICU visits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>gender_concept_id</th>\n",
       "      <th>year_of_birth</th>\n",
       "      <th>month_of_birth</th>\n",
       "      <th>day_of_birth</th>\n",
       "      <th>birth_datetime</th>\n",
       "      <th>race_concept_id</th>\n",
       "      <th>ethnicity_concept_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>provider_id</th>\n",
       "      <th>...</th>\n",
       "      <th>visit_type_concept_id</th>\n",
       "      <th>provider_id_1</th>\n",
       "      <th>care_site_id_1</th>\n",
       "      <th>visit_source_value</th>\n",
       "      <th>visit_source_concept_id</th>\n",
       "      <th>admitting_source_concept_id</th>\n",
       "      <th>admitting_source_value</th>\n",
       "      <th>discharge_to_concept_id</th>\n",
       "      <th>discharge_to_source_value</th>\n",
       "      <th>preceding_visit_occurrence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4239478333578644568</td>\n",
       "      <td>8507</td>\n",
       "      <td>2111</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>8527</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>32817</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10022880|27708593</td>\n",
       "      <td>2000001808</td>\n",
       "      <td>38004207</td>\n",
       "      <td>PHYSICIAN REFERRAL</td>\n",
       "      <td>581476</td>\n",
       "      <td>HOME</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-8090189584974691216</td>\n",
       "      <td>8507</td>\n",
       "      <td>2118</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>8527</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>32817</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10009049|22995465</td>\n",
       "      <td>2000001806</td>\n",
       "      <td>8870</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>581476</td>\n",
       "      <td>HOME</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2161418207209636934</td>\n",
       "      <td>8507</td>\n",
       "      <td>2060</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2000001401</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>32817</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10002495|24982426</td>\n",
       "      <td>2000001809</td>\n",
       "      <td>8717</td>\n",
       "      <td>TRANSFER FROM HOSPITAL</td>\n",
       "      <td>8863</td>\n",
       "      <td>SKILLED NURSING FACILITY</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1532249960797525190</td>\n",
       "      <td>8532</td>\n",
       "      <td>2106</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2000001405</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>32817</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10014078|25809882</td>\n",
       "      <td>2000001806</td>\n",
       "      <td>8870</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>581476</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2288881942133868955</td>\n",
       "      <td>8532</td>\n",
       "      <td>2102</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>8527</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>32817</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10001217|24597018</td>\n",
       "      <td>2000001806</td>\n",
       "      <td>8870</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>581476</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             person_id  gender_concept_id  year_of_birth month_of_birth  \\\n",
       "0  4239478333578644568               8507           2111           None   \n",
       "1 -8090189584974691216               8507           2118           None   \n",
       "2  2161418207209636934               8507           2060           None   \n",
       "3  1532249960797525190               8532           2106           None   \n",
       "4  2288881942133868955               8532           2102           None   \n",
       "\n",
       "  day_of_birth birth_datetime  race_concept_id  ethnicity_concept_id  \\\n",
       "0         None            NaT             8527                     0   \n",
       "1         None            NaT             8527                     0   \n",
       "2         None            NaT       2000001401                     0   \n",
       "3         None            NaT       2000001405                     0   \n",
       "4         None            NaT             8527                     0   \n",
       "\n",
       "  location_id provider_id  ... visit_type_concept_id  provider_id_1  \\\n",
       "0        None        None  ...                 32817           None   \n",
       "1        None        None  ...                 32817           None   \n",
       "2        None        None  ...                 32817           None   \n",
       "3        None        None  ...                 32817           None   \n",
       "4        None        None  ...                 32817           None   \n",
       "\n",
       "  care_site_id_1  visit_source_value visit_source_concept_id  \\\n",
       "0           None   10022880|27708593              2000001808   \n",
       "1           None   10009049|22995465              2000001806   \n",
       "2           None   10002495|24982426              2000001809   \n",
       "3           None   10014078|25809882              2000001806   \n",
       "4           None   10001217|24597018              2000001806   \n",
       "\n",
       "   admitting_source_concept_id  admitting_source_value  \\\n",
       "0                     38004207      PHYSICIAN REFERRAL   \n",
       "1                         8870          EMERGENCY ROOM   \n",
       "2                         8717  TRANSFER FROM HOSPITAL   \n",
       "3                         8870          EMERGENCY ROOM   \n",
       "4                         8870          EMERGENCY ROOM   \n",
       "\n",
       "   discharge_to_concept_id  discharge_to_source_value  \\\n",
       "0                   581476                       HOME   \n",
       "1                   581476                       HOME   \n",
       "2                     8863   SKILLED NURSING FACILITY   \n",
       "3                   581476           HOME HEALTH CARE   \n",
       "4                   581476           HOME HEALTH CARE   \n",
       "\n",
       "   preceding_visit_occurrence_id  \n",
       "0                           <NA>  \n",
       "1                           <NA>  \n",
       "2                           <NA>  \n",
       "3                           <NA>  \n",
       "4                           <NA>  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Setup observations from person + visit_occurrence\n",
    "edata = ed.io.omop.setup_obs(\n",
    "    backend_handle=con,\n",
    "    observation_table=\"person_visit_occurrence\",  # Each row = one ICU visit\n",
    ")\n",
    "\n",
    "print(f\"Created EHRData with {edata.n_obs} ICU visits\")\n",
    "edata.obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Using interval_length_unit='h' with time_precision='date' may lead to unexpected results. Consider using time_precision='datetime' for fine-grained time intervals. \n",
      "WARNING:root:multiple units for features: [[  2]\n",
      " [  8]\n",
      " [ 15]\n",
      " [ 22]\n",
      " [ 27]\n",
      " [ 32]\n",
      " [ 46]\n",
      " [ 53]\n",
      " [ 54]\n",
      " [ 56]\n",
      " [ 58]\n",
      " [ 62]\n",
      " [ 74]\n",
      " [ 75]\n",
      " [ 76]\n",
      " [ 78]\n",
      " [ 86]\n",
      " [ 99]\n",
      " [107]\n",
      " [109]\n",
      " [117]\n",
      " [132]\n",
      " [138]\n",
      " [149]\n",
      " [159]\n",
      " [217]]\n",
      "WARNING:root:Concept_ids are only partially matching. Mapping concept_ids where applicable.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EHRData object with n_obs × n_vars × n_t = 99 × 450 × 24\n",
       "    obs: 'person_id', 'gender_concept_id', 'year_of_birth', 'month_of_birth', 'day_of_birth', 'birth_datetime', 'race_concept_id', 'ethnicity_concept_id', 'location_id', 'provider_id', 'care_site_id', 'person_source_value', 'gender_source_value', 'gender_source_concept_id', 'race_source_value', 'race_source_concept_id', 'ethnicity_source_value', 'ethnicity_source_concept_id', 'visit_occurrence_id', 'person_id_1', 'visit_concept_id', 'visit_start_date', 'visit_start_datetime', 'visit_end_date', 'visit_end_datetime', 'visit_type_concept_id', 'provider_id_1', 'care_site_id_1', 'visit_source_value', 'visit_source_concept_id', 'admitting_source_concept_id', 'admitting_source_value', 'discharge_to_concept_id', 'discharge_to_source_value', 'preceding_visit_occurrence_id'\n",
       "    var: 'data_table_concept_id', 'data_table_concept_id_mapped', 'concept_id', 'concept_name', 'domain_id', 'vocabulary_id', 'concept_class_id', 'standard_concept', 'concept_code', 'valid_start_date', 'valid_end_date', 'invalid_reason'\n",
       "    tem: '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23'\n",
       "    uns: 'omop_io_observation_table', 'unit_report_measurement'\n",
       "    layers: 'measurements'\n",
       "    shape of .measurements: (99, 450, 24)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Extract measurements from the first 24 hours\n",
    "edata = ed.io.omop.setup_variables(\n",
    "    edata=edata,\n",
    "    backend_handle=con,\n",
    "    layer=\"measurements\",\n",
    "    data_tables=[\"measurement\"],\n",
    "    data_field_to_keep={\"measurement\": \"value_as_number\"},\n",
    "    interval_length_number=1,\n",
    "    interval_length_unit=\"h\",  # Hourly intervals\n",
    "    num_intervals=24,  # First 24 hours\n",
    "    aggregation_strategy=\"last\",\n",
    "    enrich_var_with_feature_info=True,\n",
    "    instantiate_tensor=True,\n",
    ")\n",
    "\n",
    "edata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for PyPOTS\n",
    "\n",
    "Extract the time series tensor - PyPOTS works directly with EHRData's `.layers` format!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time series shape: (99, 450, 24)\n",
      "Missing values: 1063929 / 1069200 (99.5%)\n"
     ]
    }
   ],
   "source": [
    "# Extract time series data: (n_patients, n_variables, n_timepoints)\n",
    "X = edata.layers[\"measurements\"]\n",
    "\n",
    "print(f\"Time series shape: {X.shape}\")\n",
    "print(f\"Missing values: {np.isnan(X).sum()} / {X.size} ({np.isnan(X).mean() * 100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Mortality Prediction with BRITS\n",
    "\n",
    "Now let's predict in-hospital mortality using BRITS, which handles missing values during classification.\n",
    "\n",
    "First, prepare the labels from OMOP's `death` table:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mortality rate: 14.1%\n",
      "Deaths: 14 / 99 patients\n"
     ]
    }
   ],
   "source": [
    "# Get death information from the database\n",
    "death_df = con.execute(\"SELECT person_id, death_datetime FROM death\").df()\n",
    "\n",
    "# Merge with our cohort to get mortality labels\n",
    "obs_with_death = edata.obs.merge(death_df, on=\"person_id\", how=\"left\", suffixes=(\"\", \"_death\"))\n",
    "\n",
    "# Create binary labels (1 = died, 0 = survived)\n",
    "y = (~obs_with_death[\"death_datetime\"].isna()).astype(int).values\n",
    "\n",
    "print(f\"Mortality rate: {y.mean() * 100:.1f}%\")\n",
    "print(f\"Deaths: {y.sum()} / {len(y)} patients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 69 patients (17.4% mortality)\n",
      "Test set: 30 patients (6.7% mortality)\n"
     ]
    }
   ],
   "source": [
    "# Split into train/test (simple split for demonstration)\n",
    "n_train = int(0.7 * len(X))\n",
    "\n",
    "X_train, X_test = X[:n_train], X[n_train:]\n",
    "y_train, y_test = y[:n_train], y[n_train:]\n",
    "\n",
    "print(f\"Training set: {len(X_train)} patients ({y_train.mean() * 100:.1f}% mortality)\")\n",
    "print(f\"Test set: {len(X_test)} patients ({y_test.mean() * 100:.1f}% mortality)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69, 450, 24)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 13:44:24 [INFO]: No given device, using default device: cpu\n",
      "2026-01-23 13:44:24 [WARNING]: ‼️ saving_path not given. Model files and tensorboard file will not be saved.\n",
      "2026-01-23 13:44:24 [INFO]: Using customized CrossEntropy as the training loss function.\n",
      "2026-01-23 13:44:24 [INFO]: Using customized CrossEntropy as the validation metric function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 13:44:24 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 2,233,780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BRITS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 13:44:25 [INFO]: Epoch 001 - training loss (CrossEntropy): 8.8671\n",
      "2026-01-23 13:44:25 [INFO]: Epoch 002 - training loss (CrossEntropy): 7.6410\n",
      "2026-01-23 13:44:25 [INFO]: Epoch 003 - training loss (CrossEntropy): 7.1593\n",
      "2026-01-23 13:44:26 [INFO]: Epoch 004 - training loss (CrossEntropy): 7.6085\n",
      "2026-01-23 13:44:26 [INFO]: Epoch 005 - training loss (CrossEntropy): 6.9683\n",
      "2026-01-23 13:44:27 [INFO]: Epoch 006 - training loss (CrossEntropy): 6.5387\n",
      "2026-01-23 13:44:28 [INFO]: Epoch 007 - training loss (CrossEntropy): 7.3746\n",
      "2026-01-23 13:44:28 [INFO]: Epoch 008 - training loss (CrossEntropy): 5.8364\n",
      "2026-01-23 13:44:29 [INFO]: Epoch 009 - training loss (CrossEntropy): 5.8552\n",
      "2026-01-23 13:44:30 [INFO]: Epoch 010 - training loss (CrossEntropy): 6.2894\n",
      "2026-01-23 13:44:30 [INFO]: Epoch 011 - training loss (CrossEntropy): 5.8102\n",
      "2026-01-23 13:44:31 [INFO]: Epoch 012 - training loss (CrossEntropy): 5.6322\n",
      "2026-01-23 13:44:32 [INFO]: Epoch 013 - training loss (CrossEntropy): 6.1972\n",
      "2026-01-23 13:44:33 [INFO]: Epoch 014 - training loss (CrossEntropy): 6.4828\n",
      "2026-01-23 13:44:33 [INFO]: Epoch 015 - training loss (CrossEntropy): 5.2483\n",
      "2026-01-23 13:44:34 [INFO]: Epoch 016 - training loss (CrossEntropy): 5.6235\n",
      "2026-01-23 13:44:34 [INFO]: Epoch 017 - training loss (CrossEntropy): 5.2900\n",
      "2026-01-23 13:44:35 [INFO]: Epoch 018 - training loss (CrossEntropy): 5.1555\n",
      "2026-01-23 13:44:35 [INFO]: Epoch 019 - training loss (CrossEntropy): 4.9370\n",
      "2026-01-23 13:44:36 [INFO]: Epoch 020 - training loss (CrossEntropy): 6.4439\n",
      "2026-01-23 13:44:36 [INFO]: Finished training. The best model is from epoch#19.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 93.3%\n",
      "Baseline (predict majority class): 93.3%\n"
     ]
    }
   ],
   "source": [
    "# Initialize BRITS classifier\n",
    "torch.manual_seed(42)\n",
    "brits = BRITS(n_steps=X.shape[2], n_features=X.shape[1], rnn_hidden_size=64, n_classes=2, epochs=20, batch_size=16)\n",
    "\n",
    "# Train the model\n",
    "print(\"Training BRITS...\")\n",
    "brits.fit({\"X\": X_train.transpose(0, 2, 1), \"y\": y_train})\n",
    "\n",
    "# Make predictions\n",
    "predictions = brits.predict({\"X\": X_test.transpose(0, 2, 1)})\n",
    "pred_labels = predictions[\"classification\"]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (pred_labels == y_test).mean()\n",
    "print(f\"\\nTest Accuracy: {accuracy * 100:.1f}%\")\n",
    "print(f\"Baseline (predict majority class): {max(y_test.mean(), 1 - y_test.mean()) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Results\n",
    "\n",
    "**What are we predicting?**\n",
    "- **Target**: In-hospital mortality (death during the ICU stay)\n",
    "- **Input**: 24 hours of vital signs and lab measurements from ICU admission\n",
    "- **Model**: BRITS learns patterns in time-series data while handling missing values\n",
    "\n",
    "**Important caveats for this demo:**\n",
    "\n",
    "```{warning}\n",
    "This demonstration uses only **100 ICU visits** from the MIMIC-IV demo dataset. Real clinical prediction models require:\n",
    "- **Much larger datasets** (thousands of patients)\n",
    "- **Careful feature engineering** and clinical domain knowledge\n",
    "- **Proper validation** (cross-validation, external validation)\n",
    "- **Clinical evaluation** and prospective testing\n",
    "\n",
    "The model performance shown here is **not clinically meaningful** due to the small sample size and simplified preprocessing. This tutorial demonstrates the *technical workflow*, not a production-ready model.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Advantages of This Approach\n",
    "\n",
    "1. **OMOP Standardization** - Same code works across different hospitals\n",
    "2. **Cohort Definition** - SQL queries filter for specific patient populations\n",
    "3. **Time-Aware Analysis** - Visit start times define temporal reference (t=0)\n",
    "4. **Missing Data Handling** - PyPOTS handles incomplete clinical data natively\n",
    "5. **Rapid Prototyping** - From database to predictions in minimal code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we learned:\n",
    "\n",
    "- ✅ How to apply PyPOTS models to OMOP data loaded via ehrdata\n",
    "- ✅ **Direct integration**: `edata.layers` can be used directly in PyPOTS without manual extraction\n",
    "- ✅ **Imputation**: Using SAITS to fill missing values in clinical time series\n",
    "- ✅ **Classification**: Using BRITS to predict mortality while handling missing data\n",
    "- ✅ The seamless workflow: **OMOP data** → **EHRData** → **PyPOTS models**\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "**Why this workflow is powerful:**\n",
    "1. **OMOP standardization** - Your code works across different hospitals' data\n",
    "2. **EHRData structure** - Clean 3D tensor format (patients × variables × time)\n",
    "3. **PyPOTS integration** - Use `edata.layers[\"measurements\"]` directly as input\n",
    "4. **Minimal code** - From database to predictions in ~30 lines\n",
    "\n",
    "## Next Tutorial\n",
    "\n",
    "Continue with **[PhysioNet 2012 Machine Learning](physionet2012_ml)** for another example of an ML prototyping workflow.\n",
    "\n",
    "## Further Resources\n",
    "\n",
    "- **[PyPOTS Documentation](https://docs.pypots.com/)** - Comprehensive documentation for PyPOTS models and utilities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ehrdata_ehrapy_env_19sep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
