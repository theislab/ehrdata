{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning on OMOP Data in `EHRData` with `PyPOTS`\n",
    "\n",
    "This tutorial demonstrates how to quickly apply machine learning to OMOP data using [PyPOTS](https://github.com/WenjieDu/PyPOTS), a powerful toolkit for time series analysis :cite:`du2023pypots`.\n",
    "\n",
    "**Prerequisites:** Complete the [OMOP Introduction tutorial](omop_intro.ipynb) first to understand how to load OMOP data into `EHRData`.\n",
    "\n",
    "## Use Case: ICU Mortality Prediction\n",
    "\n",
    "We'll predict in-hospital mortality for ICU patients using the [MIMIC-IV demo dataset in OMOP format](https://physionet.org/content/mimic-iv-demo-omop/0.9/) :cite:`reyna2020early` :cite:`goldberger2000physiobank`.\n",
    "\n",
    "```{note}\n",
    "This is a demonstration example. Real clinical prediction requires more sophisticated preprocessing, validation, and careful consideration of clinical context.\n",
    "```\n",
    "\n",
    "## What is PyPOTS?\n",
    "\n",
    "PyPOTS provides state-of-the-art neural network models for time series tasks:\n",
    "- **Imputation** - Fill missing values in incomplete time series\n",
    "- **Classification** - Predict outcomes from time series\n",
    "- **Forecasting** - Predict future values\n",
    "- **Clustering** - Group similar patients\n",
    "\n",
    "PyPOTS works seamlessly with `EHRData` objects!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pypots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyPOTS requires this for scipy compatibility\n",
    "import os\n",
    "\n",
    "os.environ[\"SCIPY_ARRAY_API\"] = \"1\"\n",
    "\n",
    "import ehrdata as ed\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pypots.classification import BRITS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Database and Download Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create database connection\n",
    "con = duckdb.connect(\":memory:\")\n",
    "\n",
    "# Download MIMIC-IV OMOP demo data\n",
    "ed.dt.mimic_iv_omop(backend_handle=con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Cohort\n",
    "\n",
    "We'll focus on ICU patients by filtering `visit_occurrence` for ICU stays using OMOP concept IDs:\n",
    "- **4305366**: Surgical ICU\n",
    "- **40481392**: Medical ICU\n",
    "- **32037**: Intensive Care\n",
    "- **763903**: Trauma ICU\n",
    "- **4149943**: Cardiac ICU\n",
    "\n",
    "We apply two key filters:\n",
    "1. **Duration**: Only ICU stays >24 hours (to ensure sufficient data for 24-hour analysis)\n",
    "2. **First visit**: If a patient had multiple ICU stays, we select their **first ICU visit**\n",
    "\n",
    "\n",
    "We do this here with SQL, operating on our (and any other) OMOP CDM database; SQL by for instance OHDSI's ATLAS tool can also be used in such a context!\n",
    "\n",
    "Alternative, the `EHRData` object can be filtered afterwards, working completely in Python (with less control over the \"raw\" data as you have it with SQL, though).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICU cohort: 99 patients (first ICU visit >24h only)\n"
     ]
    }
   ],
   "source": [
    "# Filter for first ICU visit per patient (>24 hours only)\n",
    "con.execute(\"\"\"\n",
    "    WITH RankedVisits AS (\n",
    "        SELECT\n",
    "            v.*,\n",
    "            vd.*,\n",
    "            ROW_NUMBER() OVER (PARTITION BY v.person_id ORDER BY v.visit_start_date) AS rn\n",
    "        FROM visit_occurrence v\n",
    "        JOIN visit_detail vd USING (visit_occurrence_id)\n",
    "        WHERE vd.visit_detail_concept_id IN (4305366, 40481392, 32037, 763903, 4149943)\n",
    "            AND date_diff('hour', v.visit_start_date, v.visit_end_date) > 24\n",
    "    ),\n",
    "    first_icu_visit_occurrence_id AS (\n",
    "        SELECT visit_occurrence_id\n",
    "        FROM RankedVisits\n",
    "        WHERE rn = 1\n",
    "    )\n",
    "    DELETE FROM visit_occurrence\n",
    "    WHERE visit_occurrence_id NOT IN (SELECT visit_occurrence_id FROM first_icu_visit_occurrence_id)\n",
    "\"\"\")\n",
    "\n",
    "# Check how many ICU visits remain\n",
    "n_visits = con.execute(\"SELECT COUNT(*) FROM visit_occurrence\").fetchone()[0]\n",
    "print(f\"ICU cohort: {n_visits} patients (first ICU visit >24h only)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build EHRData from OMOP\n",
    "\n",
    "Now we construct the EHRData object using **ICU visit start** as the time reference (t=0) for each patient:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created EHRData with 99 ICU visits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>gender_concept_id</th>\n",
       "      <th>year_of_birth</th>\n",
       "      <th>month_of_birth</th>\n",
       "      <th>day_of_birth</th>\n",
       "      <th>birth_datetime</th>\n",
       "      <th>race_concept_id</th>\n",
       "      <th>ethnicity_concept_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>provider_id</th>\n",
       "      <th>...</th>\n",
       "      <th>admitting_source_value</th>\n",
       "      <th>discharge_to_concept_id</th>\n",
       "      <th>discharge_to_source_value</th>\n",
       "      <th>preceding_visit_occurrence_id</th>\n",
       "      <th>death_date</th>\n",
       "      <th>death_datetime</th>\n",
       "      <th>death_type_concept_id</th>\n",
       "      <th>cause_concept_id</th>\n",
       "      <th>cause_source_value</th>\n",
       "      <th>cause_source_concept_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4239478333578644568</td>\n",
       "      <td>8507</td>\n",
       "      <td>2111</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>8527</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>PHYSICIAN REFERRAL</td>\n",
       "      <td>581476</td>\n",
       "      <td>HOME</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-8090189584974691216</td>\n",
       "      <td>8507</td>\n",
       "      <td>2118</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>8527</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>581476</td>\n",
       "      <td>HOME</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2161418207209636934</td>\n",
       "      <td>8507</td>\n",
       "      <td>2060</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2000001401</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>TRANSFER FROM HOSPITAL</td>\n",
       "      <td>8863</td>\n",
       "      <td>SKILLED NURSING FACILITY</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1532249960797525190</td>\n",
       "      <td>8532</td>\n",
       "      <td>2106</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2000001405</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>581476</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2288881942133868955</td>\n",
       "      <td>8532</td>\n",
       "      <td>2102</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>8527</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>581476</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             person_id  gender_concept_id  year_of_birth month_of_birth  \\\n",
       "0  4239478333578644568               8507           2111           None   \n",
       "1 -8090189584974691216               8507           2118           None   \n",
       "2  2161418207209636934               8507           2060           None   \n",
       "3  1532249960797525190               8532           2106           None   \n",
       "4  2288881942133868955               8532           2102           None   \n",
       "\n",
       "  day_of_birth birth_datetime  race_concept_id  ethnicity_concept_id  \\\n",
       "0         None            NaT             8527                     0   \n",
       "1         None            NaT             8527                     0   \n",
       "2         None            NaT       2000001401                     0   \n",
       "3         None            NaT       2000001405                     0   \n",
       "4         None            NaT             8527                     0   \n",
       "\n",
       "  location_id provider_id  ...  admitting_source_value  \\\n",
       "0        None        None  ...      PHYSICIAN REFERRAL   \n",
       "1        None        None  ...          EMERGENCY ROOM   \n",
       "2        None        None  ...  TRANSFER FROM HOSPITAL   \n",
       "3        None        None  ...          EMERGENCY ROOM   \n",
       "4        None        None  ...          EMERGENCY ROOM   \n",
       "\n",
       "   discharge_to_concept_id discharge_to_source_value  \\\n",
       "0                   581476                      HOME   \n",
       "1                   581476                      HOME   \n",
       "2                     8863  SKILLED NURSING FACILITY   \n",
       "3                   581476          HOME HEALTH CARE   \n",
       "4                   581476          HOME HEALTH CARE   \n",
       "\n",
       "   preceding_visit_occurrence_id death_date  death_datetime  \\\n",
       "0                           <NA>        NaT             NaT   \n",
       "1                           <NA>        NaT             NaT   \n",
       "2                           <NA>        NaT             NaT   \n",
       "3                           <NA>        NaT             NaT   \n",
       "4                           <NA>        NaT             NaT   \n",
       "\n",
       "  death_type_concept_id  cause_concept_id  cause_source_value  \\\n",
       "0                   NaN               NaN                 NaN   \n",
       "1                   NaN               NaN                 NaN   \n",
       "2                   NaN               NaN                 NaN   \n",
       "3                   NaN               NaN                 NaN   \n",
       "4                   NaN               NaN                 NaN   \n",
       "\n",
       "   cause_source_concept_id  \n",
       "0                      NaN  \n",
       "1                      NaN  \n",
       "2                      NaN  \n",
       "3                      NaN  \n",
       "4                      NaN  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Setup observations from person + visit_occurrence\n",
    "edata = ed.io.omop.setup_obs(\n",
    "    backend_handle=con,\n",
    "    observation_table=\"person_visit_occurrence\",  # Each row = one ICU visit\n",
    "    death_table=True,\n",
    ")\n",
    "\n",
    "print(f\"Created EHRData with {edata.n_obs} ICU visits\")\n",
    "edata.obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Using interval_length_unit='h' with time_precision='date' may lead to unexpected results. Consider using time_precision='datetime' for fine-grained time intervals. \n",
      "WARNING:root:multiple units for features: [[  7]\n",
      " [ 12]\n",
      " [ 16]\n",
      " [ 17]\n",
      " [ 21]\n",
      " [ 23]\n",
      " [ 27]\n",
      " [ 36]\n",
      " [ 41]\n",
      " [ 53]\n",
      " [ 55]\n",
      " [ 56]\n",
      " [ 68]\n",
      " [ 69]\n",
      " [ 73]\n",
      " [ 83]\n",
      " [ 90]\n",
      " [105]\n",
      " [109]\n",
      " [110]\n",
      " [111]\n",
      " [121]\n",
      " [126]\n",
      " [140]\n",
      " [141]\n",
      " [176]]\n",
      "WARNING:root:Concept_ids are only partially matching. Mapping concept_ids where applicable.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EHRData object with n_obs × n_vars × n_t = 99 × 450 × 24\n",
       "    obs: 'person_id', 'gender_concept_id', 'year_of_birth', 'month_of_birth', 'day_of_birth', 'birth_datetime', 'race_concept_id', 'ethnicity_concept_id', 'location_id', 'provider_id', 'care_site_id', 'person_source_value', 'gender_source_value', 'gender_source_concept_id', 'race_source_value', 'race_source_concept_id', 'ethnicity_source_value', 'ethnicity_source_concept_id', 'visit_occurrence_id', 'person_id_1', 'visit_concept_id', 'visit_start_date', 'visit_start_datetime', 'visit_end_date', 'visit_end_datetime', 'visit_type_concept_id', 'provider_id_1', 'care_site_id_1', 'visit_source_value', 'visit_source_concept_id', 'admitting_source_concept_id', 'admitting_source_value', 'discharge_to_concept_id', 'discharge_to_source_value', 'preceding_visit_occurrence_id', 'death_date', 'death_datetime', 'death_type_concept_id', 'cause_concept_id', 'cause_source_value', 'cause_source_concept_id'\n",
       "    var: 'data_table_concept_id', 'data_table_concept_id_mapped', 'concept_id', 'concept_name', 'domain_id', 'vocabulary_id', 'concept_class_id', 'standard_concept', 'concept_code', 'valid_start_date', 'valid_end_date', 'invalid_reason'\n",
       "    tem: '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23'\n",
       "    uns: 'omop_io_observation_table', 'unit_report_measurement'\n",
       "    layers: 'measurements'\n",
       "    shape of .measurements: (99, 450, 24)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Extract measurements from the first 24 hours\n",
    "edata = ed.io.omop.setup_variables(\n",
    "    edata=edata,\n",
    "    backend_handle=con,\n",
    "    layer=\"measurements\",\n",
    "    data_tables=[\"measurement\"],\n",
    "    data_field_to_keep={\"measurement\": \"value_as_number\"},\n",
    "    interval_length_number=1,\n",
    "    interval_length_unit=\"h\",  # Hourly intervals\n",
    "    num_intervals=24,  # First 24 hours\n",
    "    aggregation_strategy=\"last\",\n",
    "    enrich_var_with_feature_info=True,\n",
    "    instantiate_tensor=True,\n",
    ")\n",
    "\n",
    "edata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Mortality Prediction with BRITS\n",
    "\n",
    "Now let's predict in-hospital mortality using BRITS, which handles missing values during classification.\n",
    "\n",
    "First, prepare labels from the extracted OMOP's `death` table:\n",
    "\n",
    "For a simplistic cohort design we select only people that survived the first 24h of their ICU visit.\n",
    "\n",
    "We consider the prediction task of predicting death after 24h of their ICU visit begin up to 7 days after the end of their ICU visit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients surviving the first 24h: 99\n"
     ]
    }
   ],
   "source": [
    "# Filter for patients surviving the first 24h\n",
    "edata = edata[\n",
    "    pd.isnull(edata.obs[\"death_datetime\"])\n",
    "    | (edata.obs[\"death_datetime\"] > edata.obs[\"visit_start_date\"] + pd.Timedelta(hours=24))\n",
    "].copy()\n",
    "print(f\"Patients surviving the first 24h: {len(edata)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients dying within 7 days after ICU stay end: 10 patients\n"
     ]
    }
   ],
   "source": [
    "# Create binary labels for the prediction task\n",
    "edata.obs[\"death\"] = edata.obs[\"death_datetime\"] <= edata.obs[\"visit_end_date\"] + pd.Timedelta(days=7)\n",
    "print(f\"Patients dying within 7 days after ICU stay end: {edata.obs['death'].sum()} patients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into a train and a test set.\n",
    "Notice how small the dataset and the labels are; we emphasize that this is merely a demonstration example with publicly available data, with not enough data to derive clinically meaningful results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 49 patients (18.4% mortality)\n",
      "Test set: 50 patients (2.0% mortality)\n"
     ]
    }
   ],
   "source": [
    "# Split into train/test (simple split for demonstration)\n",
    "n_train = int(0.5 * len(edata))\n",
    "n_test = int(0.5 * len(edata)), len(edata)\n",
    "\n",
    "edata_train = edata[:n_train]\n",
    "edata_test = edata[n_train:]\n",
    "\n",
    "print(f\"Training set: {len(edata_train)} patients ({edata_train.obs['death'].mean() * 100:.1f}% mortality)\")\n",
    "print(f\"Test set: {len(edata_test)} patients ({edata_test.obs['death'].mean() * 100:.1f}% mortality)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can with a few lines of code train e.g. BRITS for our prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-24 15:04:57 [INFO]: No given device, using default device: cpu\n",
      "2026-01-24 15:04:57 [WARNING]: ‼️ saving_path not given. Model files and tensorboard file will not be saved.\n",
      "2026-01-24 15:04:57 [INFO]: Using customized CrossEntropy as the training loss function.\n",
      "2026-01-24 15:04:57 [INFO]: Using customized CrossEntropy as the validation metric function.\n",
      "2026-01-24 15:04:57 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,920,500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BRITS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-24 15:04:58 [INFO]: Epoch 001 - training loss (CrossEntropy): 9.0722\n",
      "2026-01-24 15:04:59 [INFO]: Epoch 002 - training loss (CrossEntropy): 8.2331\n",
      "2026-01-24 15:05:00 [INFO]: Epoch 003 - training loss (CrossEntropy): 19.9148\n",
      "2026-01-24 15:05:00 [INFO]: Epoch 004 - training loss (CrossEntropy): 7.2492\n",
      "2026-01-24 15:05:01 [INFO]: Epoch 005 - training loss (CrossEntropy): 7.2642\n",
      "2026-01-24 15:05:02 [INFO]: Epoch 006 - training loss (CrossEntropy): 6.9102\n",
      "2026-01-24 15:05:03 [INFO]: Epoch 007 - training loss (CrossEntropy): 6.0379\n",
      "2026-01-24 15:05:04 [INFO]: Epoch 008 - training loss (CrossEntropy): 24.0008\n",
      "2026-01-24 15:05:04 [INFO]: Epoch 009 - training loss (CrossEntropy): 7.5186\n",
      "2026-01-24 15:05:05 [INFO]: Epoch 010 - training loss (CrossEntropy): 6.5848\n",
      "2026-01-24 15:05:05 [INFO]: Finished training. The best model is from epoch#7.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 98.0%\n",
      "Baseline (predict majority class): 98.0%\n"
     ]
    }
   ],
   "source": [
    "# Initialize BRITS classifier\n",
    "torch.manual_seed(42)\n",
    "brits = BRITS(\n",
    "    n_steps=edata_train.shape[2],\n",
    "    n_features=edata_train.shape[1],\n",
    "    rnn_hidden_size=32,\n",
    "    n_classes=2,\n",
    "    epochs=10,\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training BRITS...\")\n",
    "brits.fit({\"X\": edata_train.layers[\"measurements\"].transpose(0, 2, 1), \"y\": edata_train.obs[\"death\"].values})\n",
    "\n",
    "# Make predictions\n",
    "predictions = brits.predict({\"X\": edata_test.layers[\"measurements\"].transpose(0, 2, 1)})\n",
    "pred_labels = predictions[\"classification\"]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (pred_labels == edata_test.obs[\"death\"]).mean()\n",
    "print(f\"\\nTest Accuracy: {accuracy * 100:.1f}%\")\n",
    "print(\n",
    "    f\"Baseline (predict majority class): {max(edata_test.obs['death'].mean(), 1 - edata_test.obs['death'].mean()) * 100:.1f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we quickly inspect the results, we can see what is happening on this small dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting deaths in test set labels: 0/50\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicting deaths in test set labels: {pred_labels.sum()}/{pred_labels.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model, without further weighting of sample importance, and a clear lack of data, simply learns to predict the imbalanced class \"no death\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Important caveats for this demo:**\n",
    "\n",
    "```{warning}\n",
    "This demonstration uses only **100 ICU visits** from the MIMIC-IV demo dataset. Real clinical prediction models require:\n",
    "- **Much larger datasets** (thousands of patients)\n",
    "- **Careful feature engineering** and clinical domain knowledge\n",
    "- **Proper validation** (cross-validation, external validation)\n",
    "- **Clinical evaluation** and prospective testing\n",
    "\n",
    "The model performance shown here is **not clinically meaningful** due to the small sample size and simplified preprocessing. This tutorial demonstrates the *technical workflow*, not a production-ready model.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Advantages of This Approach\n",
    "\n",
    "1. **OMOP Standardization** - Same code works across different hospitals\n",
    "2. **Cohort Definition** - SQL queries filter for specific patient populations\n",
    "3. **Time-Aware Analysis** - Visit start times define temporal reference (t=0)\n",
    "4. **Missing Data Handling** - PyPOTS handles incomplete clinical data natively\n",
    "5. **Rapid Prototyping** - From database to predictions in minimal code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we learned:\n",
    "\n",
    "- ✅ How to apply PyPOTS models to OMOP data loaded via ehrdata\n",
    "- ✅ **Direct integration**: `edata.layers` can be used directly in PyPOTS without manual extraction\n",
    "- ✅ **Imputation**: Using SAITS to fill missing values in clinical time series\n",
    "- ✅ **Classification**: Using BRITS to predict mortality while handling missing data\n",
    "- ✅ The seamless workflow: **OMOP data** → **EHRData** → **PyPOTS models**\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "**Why this workflow is powerful:**\n",
    "1. **OMOP standardization** - Your code works across different hospitals' data\n",
    "2. **EHRData structure** - Clean 3D tensor format (patients × variables × time)\n",
    "3. **PyPOTS integration** - Use `edata.layers[\"measurements\"]` directly as input\n",
    "4. **Minimal code** - From database to predictions in ~30 lines\n",
    "\n",
    "## Next Tutorial\n",
    "\n",
    "Continue with **[PhysioNet 2012 Machine Learning](physionet2012_ml)** for another example of an ML prototyping workflow.\n",
    "\n",
    "## Further Resources\n",
    "\n",
    "- **[PyPOTS Documentation](https://docs.pypots.com/)** - Comprehensive documentation for PyPOTS models and utilities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ehrdata_ehrapy_env_19sep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
